services:
  # 1. Our FastAPI Application
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ingestiq_api
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
    env_file: .env
    depends_on:
      - postgres
      - mongo
      - rabbitmq
    command: uvicorn app.main_api:app --host 0.0.0.0 --port 8000 --reload

  # 2. PostgreSQL for Metadata & State
  postgres:
    image: postgres:16-alpine
    container_name: ingestiq_postgres
    ports:
      - "5432:5432"
    volumes:
      - ./local_data/postgres_data:/var/lib/postgresql/data
    env_file: .env

  # 3. MongoDB for Raw Text Caching
  mongo:
    image: mongo:latest
    container_name: ingestiq_mongo
    ports:
      - "27017:27017"
    volumes:
      - ./local_data/mongo_data:/data/db
    env_file: .env

  # 4. RabbitMQ for Messaging
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: ingestiq_rabbitmq
    ports:
      - "5672:5672"   # For application connection
      - "15672:15672" # For web management UI

    env_file: .env

  # 5. Airflow Services
  # We use the official Airflow docker-compose setup as a template
  airflow-webserver:
    image: apache/airflow:2.9.2
    container_name: ingestiq_airflow_webserver
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=amqp://ingestiq:supersecretpassword@rabbitmq:5672/
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://ingestiq:supersecretpassword@postgres:5432/ingestiq_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - postgres
      - rabbitmq
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.9.2
    container_name: ingestiq_airflow_scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=amqp://ingestiq:supersecretpassword@rabbitmq:5672/
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://ingestiq:supersecretpassword@postgres:5432/ingestiq_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - postgres
      - rabbitmq
    command: scheduler

  airflow-worker:
    image: apache/airflow:2.9.2
    container_name: ingestiq_airflow_worker
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=amqp://ingestiq:supersecretpassword@rabbitmq:5672/
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://ingestiq:supersecretpassword@postgres:5432/ingestiq_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - airflow-scheduler
    command: celery worker

  # This service runs once to initialize the Airflow database
  airflow-init:
    image: apache/airflow:2.9.2
    container_name: ingestiq_airflow_init
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=amqp://ingestiq:supersecretpassword@rabbitmq:5672/
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://ingestiq:supersecretpassword@postgres:5432/ingestiq_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - postgres
      - rabbitmq
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin
      "

volumes:
  postgres_data:
  mongo_data:

